## GPDB   · 特性分析· GreenPlum Primary/Mirror 同步机制


PostgreSQL 主备同步机制是通过流复制实现，其原理见之前的月报[PG主备流复制机制][2]。  


Greenplum 是基于PostgreSQL开发的，它的主备也是通过流复制实现，但是Segment节点中的Primary和Mirror之间的数据同步是基于文件级别的同步实现的。为什么Primary和Mirror不能再使用流复制实现呢？主要有两个原因:  


* Append Only表不写WAL日志，所以Append Only表的数据就不能通过XLOG发送到Mirror再Apply；
* pg_control等文件也是不写WAL日志，也只能通过文件方式同步到Mirror。


## GP总体结构


Greenplum 的架构采用了MPP 无共享体系。在 MPP 系统中，每个数据节点有自己的CPU、磁盘和内存(Share nothing)，每个节点内的 CPU 不能访问另一个节点的内存。节点之间的信息交互是通过节点互联网络实现的，这个过程一般称为数据重分配(Data Redistribution)。GP master负责协调整个集群 ，一个数据节点可以配置多个节点实例(Segment Instances)，节点实例并行处理查询(SQL)。  


![][0]  

## Primary和Mirror同步机制


Primary和Mirror同步的内容主要有两部分，即文件和数据。之所以Primary和Mirror要同步文件，是Primary和Mirror之间可以自动failover，只有两者保持同步才能相互替代，如果只把数据同步过去，pg_control、pg_clog、pg_subtrans 没有同步，那么从Primary切换到Mirror会出现问题。GP master和GP slave却不用担心这些问题，Append Only 表的数据只会存在 Segment，所以WAL日志足够保持GP master和GP slave同步(只要是流复制，pg_control、pg_clog、pg_subtrans 这些文件Slave会自动更新，无需从Master同步)。  

### 数据同步


当GP master向Primary下发执行计划后，Primary开始执行，如果是DML操作，那么Primary会产生XLOG及更新page。会在`SlruPhysicalWritePage`函数中(写数据页)产生FileRepOperationOpen、FileRepOperationWrite、FileRepOperationFlush、FileRepOperationClose等指令消息(消息中包含具体要更新的文件page及内容)，通过primary sender进程向Mirror发送Message，然后Mirror的mirror consumer等进程解析消息，执行变更。XLOG通过`XLogWrite`函数(写XLOG)执行同样的操作，把XLOG更新同步过去。  

### 文件同步


Primary会有个recovery进程，这个进程会循环把Primary的 pg_control、pg_clog、pg_subtrans 等文件覆盖到Mirror。同时检查XLOG是否一致，如果不一致以Primary为主，对Mirror进行覆盖。除了把Primary部分文件同步到Mirror之外recovery进程还会将Mirror上面的临时文件删掉。  


![][1]  

## 总结


Primary和Mirror同步数据的时候，Primary对于每一次写page都会通过消息发送到Mirror，如果Primary大量的更新page，那么Primary和Mirror同步将有可能成为瓶颈。  


[2]: http://mysql.taobao.org/monthly/2015/10/04/
[0]: http://img4.tbcdn.cn/L1/461/1/25cb13dedc5719336a8e81f588afee2ace8694a7.png
[1]: http://img3.tbcdn.cn/L1/461/1/49648447a14539def95bda229d3e9672f5eba9a4.png